This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-08-07 15:39:51

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
adf_to_markdown.py
export_csv.py
export_json.py
jira_client.py
main.py
```

# Repository Files


## adf_to_markdown.py

````python
import json
from datetime import datetime

def normalize_description_to_markdown(value, options=None):
    """
    Convert Jira Description (ADF or string) to Markdown.
    Returns a string (may be empty).
    """
    opts = {
        "promote_strong_paragraphs_to_headings": True,
        "heading_level": 2,
        "emoji_style": "unicode",  # unicode or shortcode
        "list_indent_spaces": 2,
        "escape_strategy": "minimal",
        "ensure_trailing_newline": True
    }
    if options:
        opts.update(options)

    if value is None:
        return ""

    if isinstance(value, dict) and value.get("type") == "doc":
        md = _adf_doc_to_markdown(value, opts)
        return md

    if isinstance(value, str):
        s = value.replace("\r\n", "\n").rstrip()
        if opts["ensure_trailing_newline"]:
            s += "\n"
        return s

    try:
        s = json.dumps(value, ensure_ascii=False)
    except Exception:
        s = str(value)
    return s + ("\n" if opts["ensure_trailing_newline"] else "")

def _adf_doc_to_markdown(doc, opts):
    blocks = []
    for node in doc.get("content", []) or []:
        block_md = _adf_block_to_markdown(node, opts, depth=0)
        if block_md:
            blocks.append(block_md.rstrip())
    out = "\n\n".join(b for b in blocks if b is not None)
    out = _normalize_blank_lines(out)
    if opts.get("ensure_trailing_newline", True) and not out.endswith("\n"):
        out += "\n"
    return out

def _adf_block_to_markdown(node, opts, depth):
    t = node.get("type")
    if t == "paragraph":
        if opts.get("promote_strong_paragraphs_to_headings", True):
            if _is_strong_only_paragraph(node):
                text = _adf_inline_to_markdown(node.get("content", []) or [], opts)
                level = min(max(int(opts.get("heading_level", 2)), 1), 6)
                return "#" * level + " " + text.strip()
        text = _adf_inline_to_markdown(node.get("content", []) or [], opts)
        return text.strip()

    if t == "heading":
        level = min(max(node.get("attrs", {}).get("level", 2), 1), 6)
        text = _adf_inline_to_markdown(node.get("content", []) or [], opts)
        return "#" * level + " " + text.strip()

    if t == "bulletList":
        items = []
        for li in node.get("content", []) or []:
            items.extend(_adf_list_item(li, opts, ordered=False, depth=depth))
        return "\n".join(items)

    if t == "orderedList":
        items = []
        start = int(node.get("attrs", {}).get("order", 1) or 1)
        for idx, li in enumerate(node.get("content", []) or []):
            items.extend(_adf_list_item(li, opts, ordered=True, depth=depth, number=start + idx))
        return "\n".join(items)

    if t == "blockquote":
        inner = []
        for ch in node.get("content", []) or []:
            b = _adf_block_to_markdown(ch, opts, depth)
            if b:
                lines = b.splitlines() or [""]
                inner.append("\n".join(["> " + ln for ln in lines]))
        return "\n\n".join(inner)

    if t == "rule":
        return "---"

    if t == "codeBlock":
        lang = node.get("attrs", {}).get("language")
        code = _adf_text_from_inline(node.get("content", []) or [])
        fence = "```"
        header = fence + (lang if lang else "")
        return f"{header}\n{code}\n{fence}"

    if t == "panel":
        panel_type = (node.get("attrs", {}) or {}).get("panelType")
        label = f"[{panel_type}]" if panel_type else "[panel]"
        inner_blocks = []
        for ch in node.get("content", []) or []:
            inner_blocks.append(_adf_block_to_markdown(ch, opts, depth))
        inner = "\n\n".join([b for b in inner_blocks if b])
        lines = (label + " " + inner).splitlines()
        return "\n".join(["> " + ln for ln in lines])

    if t in ("mediaSingle", "mediaGroup", "media"):
        return "![attachment](attachment)"

    if t == "table":
        return _adf_table_to_markdown(node, opts)

    if t == "taskList":
        items = []
        indent = " " * (opts.get("list_indent_spaces", 2) * depth)
        for it in node.get("content", []) or []:
            checked = (it.get("attrs", {}) or {}).get("state") == "DONE"
            box = "[x]" if checked else "[ ]"
            text = ""
            for ch in it.get("content", []) or []:
                if ch.get("type") == "paragraph":
                    text = _adf_inline_to_markdown(ch.get("content", []) or [], opts).strip()
            items.append(f"{indent}- {box} {text}")
        return "\n".join(items)

    if "content" in node:
        parts = []
        for ch in node.get("content", []) or []:
            parts.append(_adf_block_to_markdown(ch, opts, depth))
        return "\n\n".join([p for p in parts if p])
    return ""

def _adf_list_item(node, opts, ordered, depth, number=None):
    lines = []
    indent = " " * (opts.get("list_indent_spaces", 2) * depth)
    bullet = f"{number}. " if ordered else "- "
    content = node.get("content", []) or []
    first_line_done = False
    for ch in content:
        if ch.get("type") == "paragraph":
            text = _adf_inline_to_markdown(ch.get("content", []) or [], opts).strip()
            if not first_line_done:
                lines.append(f"{indent}{bullet}{text}")
                first_line_done = True
            else:
                lines.append(f"{indent}{' ' * len(bullet)}{text}")
        elif ch.get("type") in ("bulletList", "orderedList", "taskList"):
            nested = _adf_block_to_markdown(ch, opts, depth + 1)
            if nested:
                lines.append(nested)
        else:
            txt = _adf_block_to_markdown(ch, opts, depth)
            if txt:
                if not first_line_done:
                    lines.append(f"{indent}{bullet}{txt}")
                    first_line_done = True
                else:
                    lines.append(f"{indent}{' ' * len(bullet)}{txt}")
    if not first_line_done:
        lines.append(f"{indent}{bullet}")
    return lines

def _adf_inline_to_markdown(inlines, opts):
    out = []
    for node in inlines:
        t = node.get("type")
        if t == "text":
            text = node.get("text", "")
            marks = node.get("marks", []) or []
            out.append(_apply_marks(text, marks, opts))
        elif t == "hardBreak":
            out.append("\n")
        elif t == "emoji":
            out.append(_render_emoji(node.get("attrs", {}) or {}, opts))
        elif t == "mention":
            attrs = node.get("attrs", {}) or {}
            label = attrs.get("text") or attrs.get("id") or "mention"
            out.append("@" + label)
        elif t in ("inlineCard", "blockCard"):
            attrs = node.get("attrs", {}) or {}
            url = attrs.get("url") or (attrs.get("data", {}) or {}).get("url")
            if url:
                title = (attrs.get("data", {}) or {}).get("name") or url
                out.append(f"[{_escape_md(title)}]({url})")
            else:
                out.append("[card]")
        elif t == "date":
            attrs = node.get("attrs", {}) or {}
            ts = attrs.get("timestamp")
            if ts:
                try:
                    dt = datetime.fromtimestamp(int(ts) / 1000.0)
                    out.append(dt.strftime("%Y-%m-%d"))
                except Exception:
                    out.append(_escape_md(str(ts)))
            else:
                out.append("[date]")
        elif t == "status":
            attrs = node.get("attrs", {}) or {}
            txt = attrs.get("text") or ""
            color = attrs.get("color")
            if color:
                out.append(f"[status: {_escape_md(txt)} ({color})]")
            else:
                out.append(f"[status: {_escape_md(txt)}]")
        else:
            out.append(_escape_md(str(node.get("text", ""))))
    return "".join(out)

def _is_strong_only_paragraph(node):
    content = node.get("content", []) or []
    if len(content) != 1 or content[0].get("type") != "text":
        return False
    marks = content[0].get("marks", []) or []
    if not content[0].get("text", "").strip():
        return False
    return all(m.get("type") == "strong" for m in marks) and len(marks) >= 1

def _apply_marks(text, marks, opts):
    if not marks:
        return _escape_md(text)

    has_code = any(m.get("type") == "code" for m in marks)
    if has_code:
        return f"`{_escape_backticks(text)}`"

    wrapped = _escape_md(text)
    types = [m.get("type") for m in marks if m.get("type")]
    if "link" in types:
        link_mark = next((m for m in marks if m.get("type") == "link"), None)
        href = (link_mark.get("attrs") or {}).get("href") if link_mark else None
        title = (link_mark.get("attrs") or {}).get("title") if link_mark else None
        label = wrapped
        if href:
            if title:
                wrapped = f"[{label}]({href} \"{_escape_quotes(title)}\")"
            else:
                wrapped = f"[{label}]({href})"
        types = [t for t in types if t != "link"]

    if "strong" in types:
        wrapped = f"**{wrapped}**"
    if "em" in types:
        wrapped = f"_{wrapped}_"
    if "strike" in types:
        wrapped = f"~~{wrapped}~~"

    return wrapped

def _escape_md(s):
    if not s:
        return ""
    specials = "\\`*_{}[]()#+-|!>"
    out = []
    for ch in s:
        if ch in specials:
            out.append("\\" + ch)
        else:
            out.append(ch)
    return "".join(out)

def _escape_backticks(s):
    return s.replace("`", "\\`")

def _escape_quotes(s):
    return s.replace('"', '\\"')

def _render_emoji(attrs, opts):
    style = opts.get("emoji_style", "unicode")
    txt = attrs.get("text") or attrs.get("shortName") or ""
    if style == "shortcode":
        return txt or ""
    id_ = attrs.get("id")
    mapping = {
        "atlassian-plus": "‚ûï",
        "atlassian-warning": "‚ö†Ô∏è",
    }
    if id_ in mapping:
        return mapping[id_]
    short = (attrs.get("shortName") or "").strip(":")
    known = {"plus": "‚ûï", "warning": "‚ö†Ô∏è"}
    if short in known:
        return known[short]
    return txt if txt else "üôÇ"

def _normalize_blank_lines(s):
    lines = s.replace("\r\n", "\n").split("\n")
    out = []
    blank = False
    for ln in lines:
        ln = ln.rstrip()
        if ln == "":
            if not blank:
                out.append("")
            blank = True
        else:
            out.append(ln)
            blank = False
    return "\n".join(out)

def _adf_text_from_inline(inlines):
    parts = []
    for node in inlines:
        if node.get("type") == "text":
            parts.append(node.get("text", ""))
        elif node.get("type") == "hardBreak":
            parts.append("\n")
    return "".join(parts)

def _adf_table_to_markdown(node, opts):
    rows = node.get("content", []) or []
    if not rows:
        return ""
    first_row = rows[0]
    is_header = any(cell.get("type") == "tableHeader" for cell in (first_row.get("content", []) or []))
    md_rows = []

    def render_cell(cell):
        txt = ""
        for ch in cell.get("content", []) or []:
            if ch.get("type") == "paragraph":
                txt += _adf_inline_to_markdown(ch.get("content", []) or [], opts).strip()
        return txt

    for r in rows:
        cells = []
        for cell in (r.get("content", []) or []):
            cells.append(render_cell(cell))
        md_rows.append("| " + " | ".join(cells) + " |")

    if is_header:
        cols = len((first_row.get("content", []) or []))
        sep = "| " + " | ".join(["---"] * cols) + " |"
        md_rows.insert(1, sep)
    return "\n".join(md_rows)
````

## export_csv.py

```python
import csv
import threading
from queue import Queue
from datetime import datetime
from dateutil import parser as dtparser, tz

CONCURRENT_WORKERS = 12  # keep default

def extract_status_changes(issue):
    changes = []
    histories = issue.get("changelog", {}).get("histories", [])
    for h in histories:
        when = dtparser.parse(h.get("created"))
        for item in h.get("items", []):
            if item.get("field") == "status":
                frm = item.get("fromString")
                to = item.get("toString")
                changes.append((frm, to, when))
    changes.sort(key=lambda x: x[2])
    return changes

def compute_time_in_status(issue, bh_overlap_fn, bh_cfg=None):
    changes = extract_status_changes(issue)
    fields = issue.get("fields", {})
    created = dtparser.parse(fields.get("created")) if fields.get("created") else None
    current_status = fields.get("status", {}).get("name")
    segments = []
    if changes:
        first_change_time = changes[0][2]
        initial_status = changes[0][0] or fields.get("status", {}).get("name")
        if created:
            segments.append((initial_status, created, first_change_time))
        for (frm, to, when), nxt in zip(changes, changes[1:] + [(None, None, None)]):
            next_time = nxt[2] if nxt != (None, None, None) else datetime.now(tz=when.tzinfo or tz.UTC)
            segments.append((to, when, next_time))
    else:
        if created and current_status:
            segments.append((current_status, created, datetime.now(tz=created.tzinfo or tz.UTC)))
    totals = {}
    for status, s, e in segments:
        if not status or not s or not e:
            continue
        hours = (e - s).total_seconds() / 3600.0
        if bh_cfg and bh_overlap_fn:
            hours = bh_overlap_fn(s, e, bh_cfg)
        totals[status] = totals.get(status, 0.0) + max(0.0, hours)
    return totals

def count_sequence_occurrences(changes, sequence):
    if not sequence or len(sequence) < 2:
        return 0
    count = 0
    i = 0
    n = len(changes)
    pair_index = 0
    needed_pairs = [(sequence[k], sequence[k+1]) for k in range(len(sequence)-1)]
    while i < n:
        frm, to, when = changes[i]
        need_from, need_to = needed_pairs[pair_index]
        if frm == need_from and to == need_to:
            pair_index += 1
            if pair_index == len(needed_pairs):
                count += 1
                pair_index = 0
        else:
            pair_index = 0
            first_from, first_to = needed_pairs[0]
            if frm == first_from and to == first_to:
                pair_index = 1
        i += 1
    return count

def get_comment_metrics(issue):
    comments = issue.get("fields", {}).get("comment", {}).get("comments", [])
    count = len(comments)
    total_length = 0
    commenters = set()
    for c in comments:
        body = c.get("body")
        if isinstance(body, dict) and "content" in body:
            import json as _json
            body_str = _json.dumps(body)
        else:
            body_str = str(body) if body is not None else ""
        total_length += len(body_str)
        author = c.get("author", {}).get("displayName") or c.get("author", {}).get("accountId")
        if author:
            commenters.add(author)
    return {
        "comment_count": count,
        "comment_length": total_length,
        "commenter_count": len(commenters),
    }

def export_csv(jira_client, jql, cfg, field_id_to_name, format_field_fn, business_hours_overlap, progress_cb):
    """
    progress_cb(stage: str, done: int, total: int)
    """
    # Stage 0: resolve keys
    keys, _ = jira_client.search_jql(jql, max_results=100, fields=["key"], expand_changelog=False)
    total = len(keys)

    q = Queue()
    for key in keys:
        q.put(key)
    results = []
    all_statuses = set()
    lock = threading.Lock()
    done_count = 0

    m = cfg.get("metrics", {})
    bh_cfg = cfg.get("business_hours", {})
    sel_ids = cfg.get("selected_field_ids") or cfg.get("selected_fields", [])
    trules = cfg.get("transition_rules", [])

    progress_cb("Stage 1/2: Downloading issues...", 0, total)

    def worker():
        nonlocal done_count
        while True:
            try:
                key = q.get_nowait()
            except Exception:
                return
            try:
                issue = jira_client.get_issue(key, expand_changelog=True)
                fields = issue.get("fields", {}) or {}

                row_fields = {}
                for fid in sel_ids:
                    row_fields[field_id_to_name.get(fid, fid)] = format_field_fn(fid, fields.get(fid))

                changes = extract_status_changes(issue)
                tr_counts = {}
                for tr in trules:
                    seq = tr.get("sequence", [])
                    tr_counts[tr["name"]] = count_sequence_occurrences(changes, seq)

                cm = get_comment_metrics(issue) if m.get("comment_count") or m.get("comment_length") or m.get("commenter_count") else {}
                tis = compute_time_in_status(issue, business_hours_overlap, bh_cfg) if m.get("time_in_status") else {}

                with lock:
                    if tis:
                        all_statuses.update(tis.keys())
                    results.append({
                        "key": issue.get("key"),
                        "fields": row_fields,
                        "tr": tr_counts,
                        "cm": cm,
                        "tis": tis
                    })
                    done_count += 1
            except Exception as e:
                with lock:
                    results.append({
                        "key": key,
                        "fields": {},
                        "tr": {},
                        "cm": {},
                        "tis": {},
                        "error": str(e)
                    })
                    done_count += 1
            finally:
                q.task_done()
                progress_cb("Stage 1/2: Downloading issues...", done_count, total)

    threads = [threading.Thread(target=worker, daemon=True) for _ in range(CONCURRENT_WORKERS)]
    for t in threads:
        t.start()
    q.join()

    # Stage 2: Build CSV content in-memory and return it to caller to write
    progress_cb("Stage 2/2: Writing CSV...", 0, total)

    sel_names = [field_id_to_name.get(fid, fid) for fid in sel_ids]
    headers = ["key"]
    headers.extend(sel_names)
    for tr in trules:
        headers.append(tr["name"])
    if m.get("comment_count"): headers.append("comment_count")
    if m.get("comment_length"): headers.append("comment_length")
    if m.get("commenter_count"): headers.append("commenter_count")
    all_statuses_sorted = sorted(list(all_statuses))
    if m.get("time_in_status"):
        headers.extend([f"TIS: {st}" for st in all_statuses_sorted])

    # Return a generator of rows so UI can stream-write and update progress
    def row_iter():
        for idx, rec in enumerate(sorted(results, key=lambda r: r.get("key") or "")):
            row = {"key": rec.get("key")}
            for name in sel_names:
                row[name] = rec["fields"].get(name, "")
            for tr in trules:
                row[tr["name"]] = rec["tr"].get(tr["name"], 0)
            if m.get("comment_count"): row["comment_count"] = rec["cm"].get("comment_count", 0)
            if m.get("comment_length"): row["comment_length"] = rec["cm"].get("comment_length", 0)
            if m.get("commenter_count"): row["commenter_count"] = rec["cm"].get("commenter_count", 0)
            if m.get("time_in_status"):
                for st in all_statuses_sorted:
                    row[f"TIS: {st}"] = round(rec["tis"].get(st, 0.0), 2)
            progress_cb("Stage 2/2: Writing CSV...", idx + 1, total)
            yield row

    return headers, row_iter
```

## export_json.py

```python
import json
from urllib.parse import quote
from datetime import datetime
from dateutil import parser as dtparser
from adf_to_markdown import normalize_description_to_markdown

def export_json(jira_client, jql, field_id_to_name, folder_path, progress_cb):
    keys, _ = jira_client.search_jql(jql, max_results=100, fields=["key"], expand_changelog=False)
    total = len(keys)
    progress_cb("Exporting JSON...", 0, total)

    for idx, key in enumerate(keys):
        issue = jira_client.get_issue(key, expand_changelog=True)

        fields = issue.get("fields", {}) or {}
        comments_block = fields.get("comment")
        total_comments = (comments_block or {}).get("total")
        if comments_block is None or total_comments is None or total_comments > len((comments_block or {}).get("comments", [])):
            full_comments = jira_client.get_all_comments(key)
            fields["comment"] = {
                "comments": full_comments,
                "total": len(full_comments),
                "maxResults": len(full_comments),
                "startAt": 0,
                "self": f"{jira_client.base_url}/rest/api/3/issue/{quote(key)}/comment"
            }

        # Description normalization
        desc_adf_or_text = fields.get("description")
        desc_md = normalize_description_to_markdown(desc_adf_or_text, options={
            "promote_strong_paragraphs_to_headings": True,
            "heading_level": 2,
            "emoji_style": "unicode",
            "list_indent_spaces": 2,
            "escape_strategy": "minimal",
            "ensure_trailing_newline": True
        })

        transformed_fields = {}
        for fid, value in fields.items():
            disp = field_id_to_name.get(fid, fid)
            if fid == "description":
                transformed_fields["description_raw"] = value
                transformed_fields["description_markdown"] = desc_md
            else:
                transformed_fields[disp] = value

        out = {
            "key": issue.get("key"),
            "id": issue.get("id"),
            "self": issue.get("self"),
            "fields": transformed_fields,
            "changelog": issue.get("changelog"),
            "meta": {
                "fieldIdMap": field_id_to_name
            }
        }

        # Save JSON file
        out_path = f"{folder_path}/{key}.json"
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(out, f, indent=2, ensure_ascii=False)

        # Create and save Markdown file
        markdown_content = create_markdown_content(issue, fields, field_id_to_name, desc_md)
        md_path = f"{folder_path}/{key}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)

        progress_cb("Exporting JSON...", idx + 1, total)

def create_markdown_content(issue, fields, field_id_to_name, description_md):
    """Create markdown content for an issue"""
    
    # Get summary
    summary = fields.get("summary", "No Summary")
    
    # Process comments
    comments = fields.get("comment", {}).get("comments", [])
    
    # Start building markdown
    md_lines = []
    
    # Title (Summary)
    md_lines.append(f"# {summary}")
    md_lines.append("")
    
    # Description section
    md_lines.append("# Description")
    md_lines.append("")
    if description_md.strip():
        # Remove extra newlines and format properly
        desc_clean = description_md.replace('\\n', '\n').strip()
        md_lines.append(desc_clean)
    else:
        md_lines.append("_No description provided_")
    md_lines.append("")
    
    # Related Work Items section
    md_lines.append("# Related Work Items")
    md_lines.append("")
    
    related_items = []
    
    # Check for subtasks
    subtasks = fields.get("subtasks", [])
    if subtasks:
        for subtask in subtasks:
            key = subtask.get("key", "")
            summary = subtask.get("fields", {}).get("summary", "")
            status = subtask.get("fields", {}).get("status", {}).get("name", "")
            if key:
                related_items.append(f"- **Subtask**: [{key}] {summary} ({status})")
    
    # Check for parent (if this is a subtask)
    parent = fields.get("parent")
    if parent:
        parent_key = parent.get("key", "")
        parent_summary = parent.get("fields", {}).get("summary", "")
        if parent_key:
            related_items.append(f"- **Parent**: [{parent_key}] {parent_summary}")
    
    # Check for issue links
    issue_links = fields.get("issuelinks", [])
    if issue_links:
        for link in issue_links:
            link_type = link.get("type", {}).get("name", "Related")
            
            # Check if this issue is the inward or outward link
            if "inwardIssue" in link:
                related_issue = link["inwardIssue"]
                direction = link.get("type", {}).get("inward", "relates to")
            elif "outwardIssue" in link:
                related_issue = link["outwardIssue"]
                direction = link.get("type", {}).get("outward", "relates to")
            else:
                continue
            
            related_key = related_issue.get("key", "")
            related_summary = related_issue.get("fields", {}).get("summary", "")
            related_status = related_issue.get("fields", {}).get("status", {}).get("name", "")
            
            if related_key:
                related_items.append(f"- **{direction.title()}**: [{related_key}] {related_summary} ({related_status})")
    
    # Check for epic link
    epic_link = fields.get("customfield_10014") or fields.get("epic link") or fields.get("Epic Link")
    if epic_link:
        if isinstance(epic_link, dict):
            epic_key = epic_link.get("key", "")
            epic_summary = epic_link.get("fields", {}).get("summary", "")
            if epic_key:
                related_items.append(f"- **Epic**: [{epic_key}] {epic_summary}")
        elif isinstance(epic_link, str) and epic_link.strip():
            related_items.append(f"- **Epic**: {epic_link}")
    
    # Check if this IS an epic with child issues
    # Note: This would require additional API calls to get epic children
    # For now, we'll just note if this issue is an epic
    issue_type = fields.get("issuetype", {}).get("name", "")
    if issue_type.lower() == "epic":
        related_items.append("- **Type**: This is an Epic (child issues not listed)")
    
    if related_items:
        md_lines.extend(related_items)
    else:
        md_lines.append("_No related work items found_")
    
    md_lines.append("")
    
    # Comments section
    if comments:
        md_lines.append("# Comments")
        md_lines.append("")
        
        for comment in comments:
            # Get author info
            author = comment.get("author", {})
            author_name = author.get("displayName") or author.get("name") or author.get("accountId", "Unknown Author")
            
            # Get and format date
            created_str = comment.get("created", "")
            try:
                if created_str:
                    created_dt = dtparser.parse(created_str)
                    date_str = created_dt.strftime("%Y-%m-%d")
                    time_str = created_dt.strftime("%H:%M")
                else:
                    date_str = "Unknown Date"
                    time_str = "Unknown Time"
            except:
                date_str = "Unknown Date"
                time_str = "Unknown Time"
            
            # Comment header
            md_lines.append(f"## {author_name} | {date_str} | {time_str}")
            md_lines.append("")
            
            # Convert comment body to markdown
            comment_body = comment.get("body")
            comment_md = normalize_description_to_markdown(comment_body, options={
                "promote_strong_paragraphs_to_headings": False,  # Don't promote headings in comments
                "heading_level": 4,  # Use smaller headings in comments
                "emoji_style": "unicode",
                "list_indent_spaces": 2,
                "escape_strategy": "minimal",
                "ensure_trailing_newline": True
            })
            
            if comment_md.strip():
                # Clean up the markdown formatting
                comment_clean = comment_md.replace('\\n', '\n').strip()
                md_lines.append(comment_clean)
            else:
                md_lines.append("_No comment body_")
            
            md_lines.append("")
    
    return "\n".join(md_lines)
```

## jira_client.py

```python
import time
import requests

class JiraClient:
    def __init__(self, base_url, email, api_token, log_fn=lambda msg: None):
        self.base_url = base_url.rstrip("/")
        self.session = requests.Session()
        self.session.auth = (email, api_token)
        self.log = log_fn

    def test_connection(self):
        try:
            url = f"{self.base_url}/rest/api/3/myself"
            r = self.session.get(url, timeout=15)
            return r.status_code == 200
        except Exception:
            return False

    def get_fields(self):
        url = f"{self.base_url}/rest/api/3/field"
        r = self.session.get(url, timeout=30)
        r.raise_for_status()
        return r.json()

    def get_issue(self, key, expand_changelog=True):
        url = f"{self.base_url}/rest/api/3/issue/{key}"
        params = {}
        if expand_changelog:
            params["expand"] = "changelog"
        r = self.session.get(url, params=params, timeout=60)
        if r.status_code == 429:
            retry_after = int(r.headers.get("Retry-After", "2"))
            time.sleep(min(10, max(1, retry_after)))
            r = self.session.get(url, params=params, timeout=60)
        r.raise_for_status()
        return r.json()

    def search_jql(self, jql, max_results=50, fields=None, expand_changelog=False):
        url = f"{self.base_url}/rest/api/3/search"
        start_at = 0
        total = None
        issue_keys = []
        expand = ["changelog"] if expand_changelog else []
        body_fields = fields if fields is not None else []
        while total is None or start_at < total:
            payload = {
                "jql": jql,
                "startAt": start_at,
                "maxResults": max_results,
                "fields": body_fields,
                "expand": expand
            }
            r = self.session.post(url, json=payload, timeout=60)
            if r.status_code == 429:
                retry_after = int(r.headers.get("Retry-After", "2"))
                time.sleep(min(10, max(1, retry_after)))
                r = self.session.post(url, json=payload, timeout=60)
            r.raise_for_status()
            data = r.json()
            total = data.get("total", 0)
            for issue in data.get("issues", []):
                issue_keys.append(issue["key"])
            start_at += max_results
        return issue_keys, total

    def get_all_comments(self, issue_key):
        url = f"{self.base_url}/rest/api/3/issue/{issue_key}/comment"
        start_at = 0
        all_comments = []
        while True:
            params = {"startAt": start_at, "maxResults": 100}
            r = self.session.get(url, params=params, timeout=60)
            if r.status_code == 429:
                retry_after = int(r.headers.get("Retry-After", "2"))
                time.sleep(min(10, max(1, retry_after)))
                r = self.session.get(url, params=params, timeout=60)
            r.raise_for_status()
            data = r.json()
            comments = data.get("comments", [])
            all_comments.extend(comments)
            if start_at + data.get("maxResults", 0) >= data.get("total", 0):
                break
            start_at += data.get("maxResults", 0)
        return all_comments
```

## main.py

```python
import os
import json
import threading
from datetime import datetime, timedelta
from dateutil import parser as dtparser, tz
import pytz
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import re

from jira_client import JiraClient
from export_csv import export_csv
from export_json import export_json

APP_DIR = os.path.join(os.path.expanduser("~"), ".jira_metrics")
CREDS_PATH = os.path.join(APP_DIR, "credentials.json")
CONFIG_DIR = os.path.join(APP_DIR, "configs")

def ensure_app_dirs():
    os.makedirs(APP_DIR, exist_ok=True)
    os.makedirs(CONFIG_DIR, exist_ok=True)

def load_credentials():
    if os.path.exists(CREDS_PATH):
        with open(CREDS_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def save_credentials(base_url, email, api_token):
    ensure_app_dirs()
    with open(CREDS_PATH, "w", encoding="utf-8") as f:
        json.dump({"base_url": base_url, "email": email, "api_token": api_token}, f)

def list_configs():
    ensure_app_dirs()
    names = []
    for fn in os.listdir(CONFIG_DIR):
        if fn.endswith(".json"):
            names.append(fn[:-5])
    return sorted(names)

def load_config(name):
    path = os.path.join(CONFIG_DIR, f"{name}.json")
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def save_config(cfg):
    ensure_app_dirs()
    name = cfg.get("name", "config")
    path = os.path.join(CONFIG_DIR, f"{name}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(cfg, f, indent=2)

def parse_time_hhmm(s):
    return datetime.strptime(s, "%H:%M").time()

def business_hours_overlap(start_dt, end_dt, bh):
    import pytz as _pytz
    tzname = bh.get("timezone", "UTC")
    tzinfo = _pytz.timezone(tzname)
    start_dt = start_dt.astimezone(tzinfo)
    end_dt = end_dt.astimezone(tzinfo)
    if end_dt <= start_dt:
        return 0.0
    start_time = parse_time_hhmm(bh.get("start", "09:00"))
    end_time = parse_time_hhmm(bh.get("end", "17:00"))
    exclude_weekends = bh.get("exclude_weekends", True)
    holidays = set()
    for h in bh.get("holidays", []):
        try:
            holidays.add(datetime.strptime(h, "%Y-%m-%d").date())
        except Exception:
            pass

    total = 0.0
    cur = start_dt.date()
    while cur <= end_dt.date():
        if not (exclude_weekends and cur.weekday() >= 5) and cur not in holidays:
            day_start = tzinfo.localize(datetime.combine(cur, start_time))
            day_end = tzinfo.localize(datetime.combine(cur, end_time))
            seg_start = max(start_dt, day_start)
            seg_end = min(end_dt, day_end)
            if seg_end > seg_start:
                total += (seg_end - seg_start).total_seconds() / 3600.0
        cur += timedelta(days=1)
    return total

class LogConsole(tk.Text):
    def __init__(self, master, **kwargs):
        super().__init__(master, **kwargs)
        self.configure(state="disabled", wrap="word")
        self.tag_config("err", foreground="red")
        self.tag_config("info", foreground="black")
    def write(self, msg, level="info"):
        self.configure(state="normal")
        self.insert("end", msg + "\n", level)
        self.see("end")
        self.configure(state="disabled")

class LoginWindow(tk.Toplevel):
    def __init__(self, master, on_success, log_fn):
        super().__init__(master)
        self.title("Jira Metrics - Login")
        self.resizable(False, False)
        self.on_success = on_success
        self.log = log_fn

        frm = ttk.Frame(self, padding=10)
        frm.grid(row=0, column=0, sticky="nsew")

        ttk.Label(frm, text="Jira URL:").grid(row=0, column=0, sticky="w")
        self.url_var = tk.StringVar()
        ttk.Entry(frm, textvariable=self.url_var, width=40).grid(row=0, column=1, columnspan=2, sticky="we")

        ttk.Label(frm, text="Email:").grid(row=1, column=0, sticky="w")
        self.email_var = tk.StringVar()
        ttk.Entry(frm, textvariable=self.email_var, width=40).grid(row=1, column=1, columnspan=2, sticky="we")

        ttk.Label(frm, text="API Token:").grid(row=2, column=0, sticky="w")
        self.token_var = tk.StringVar()
        ttk.Entry(frm, textvariable=self.token_var, width=40, show="*").grid(row=2, column=1, columnspan=2, sticky="we")

        self.btn_login = ttk.Button(frm, text="Login", command=self.do_login)
        self.btn_login.grid(row=3, column=1, sticky="we", pady=(8, 0))
        self.btn_use_saved = ttk.Button(frm, text="Use Saved Credentials", command=self.use_saved)
        self.btn_use_saved.grid(row=3, column=2, sticky="we", pady=(8, 0))

        creds = load_credentials()
        if creds:
            self.url_var.set(creds.get("base_url", ""))
            self.email_var.set(creds.get("email", ""))

        self.grab_set()
        self.protocol("WM_DELETE_WINDOW", self.destroy)

    def use_saved(self):
        creds = load_credentials()
        if not creds:
            messagebox.showerror("Error", "No saved credentials found.")
            return
        client = JiraClient(creds["base_url"], creds["email"], creds["api_token"], log_fn=self.log)
        self.log("Testing saved credentials...")
        if client.test_connection():
            self.log("Login success with saved credentials.")
            self.on_success(client)
            self.destroy()
        else:
            messagebox.showerror("Login Failed", "Saved credentials are invalid.")

    def do_login(self):
        base_url = self.url_var.get().strip()
        email = self.email_var.get().strip()
        token = self.token_var.get().strip()
        if not base_url or not email or not token:
            messagebox.showerror("Error", "Please enter URL, Email, and API Token.")
            return
        client = JiraClient(base_url, email, token, log_fn=self.log)
        self.log("Testing credentials...")
        self.btn_login.configure(state="disabled")
        def worker():
            return client.test_connection()
        def on_done(ok):
            self.btn_login.configure(state="normal")
            if ok:
                self.log("Login success.")
                save_credentials(base_url, email, token)
                self.on_success(client)
                self.destroy()
            else:
                messagebox.showerror("Login Failed", "Invalid credentials or URL.")
        threading.Thread(target=lambda: self._run_worker(worker, on_done), daemon=True).start()

    def _run_worker(self, worker, on_done):
        try:
            ok = worker()
        except Exception as e:
            self.log(f"Login error: {e}")
            ok = False
        finally:
            self.after(0, lambda: on_done(ok))

class ConfigTab(ttk.Frame):
    def __init__(self, master, jira_client: JiraClient, log_fn, field_id_to_name, field_name_to_id):
        super().__init__(master)
        self.client = jira_client
        self.log = log_fn
        self.field_id_to_name = field_id_to_name
        self.field_name_to_id = field_name_to_id

        self.available_field_ids = []
        self.selected_field_ids = set()

        self.transition_rules = []
        self.metrics_flags = {
            "comment_count": tk.BooleanVar(value=True),
            "comment_length": tk.BooleanVar(value=True),
            "commenter_count": tk.BooleanVar(value=True),
            "time_in_status": tk.BooleanVar(value=True),
        }

        self._build_ui()

    def _build_ui(self):
        left = ttk.LabelFrame(self, text="Fields", padding=8)
        left.grid(row=0, column=0, sticky="nsew", padx=(0,8), pady=8)

        ttk.Label(left, text="Enter an Issue Key to load fields:").grid(row=0, column=0, sticky="w")
        self.issue_key_var = tk.StringVar()
        ttk.Entry(left, textvariable=self.issue_key_var, width=25).grid(row=0, column=1, sticky="we")
        ttk.Button(left, text="Load Fields", command=self.load_fields).grid(row=0, column=2, sticky="we", padx=(6,0))

        cols = ("selected", "field", "value")
        self.fields_tree = ttk.Treeview(left, columns=cols, show="headings", height=16)
        self.fields_tree.heading("selected", text="‚úî")
        self.fields_tree.heading("field", text="Field")
        self.fields_tree.heading("value", text="Example Value")
        self.fields_tree.column("selected", width=40, anchor="center")
        self.fields_tree.column("field", width=260, anchor="w")
        self.fields_tree.column("value", anchor="w")
        self.fields_tree.grid(row=1, column=0, columnspan=3, sticky="nsew", pady=(6,0))
        left.grid_columnconfigure(1, weight=1)
        left.grid_rowconfigure(1, weight=1)

        self.fields_tree.bind("<Button-1>", self._on_tree_click)

        right = ttk.LabelFrame(self, text="Metrics", padding=8)
        right.grid(row=0, column=1, sticky="nsew", pady=8)

        trlf = ttk.LabelFrame(right, text="Custom Status Transition Rules")
        trlf.grid(row=0, column=0, sticky="nsew", pady=(0,8))
        self.tr_container = ttk.Frame(trlf)
        self.tr_container.grid(row=0, column=0, sticky="nsew")
        self.tr_rows = []

        def add_rule_row(prefill=None):
            row = ttk.Frame(self.tr_container)
            name_var = tk.StringVar(value=(prefill.get("name") if prefill else ""))
            ttk.Label(row, text="Name:").grid(row=0, column=0, sticky="w")
            name_entry = ttk.Entry(row, textvariable=name_var, width=20)
            name_entry.grid(row=0, column=1, sticky="w")
            seq_frame = ttk.Frame(row)
            seq_frame.grid(row=0, column=2, padx=(8,8))
            seq_vars = []
            def add_box(value=""):
                v = tk.StringVar(value=value)
                ent = ttk.Entry(seq_frame, textvariable=v, width=18)
                if len(seq_vars) > 0:
                    ttk.Label(seq_frame, text="‚Üí").pack(side="left")
                ent.pack(side="left")
                seq_vars.append(v)
            def on_plus():
                add_box("")
            plus_btn = ttk.Button(row, text="+", width=3, command=on_plus)
            plus_btn.grid(row=0, column=3)
            def on_delete():
                row.destroy()
                self.tr_rows.remove((name_var, seq_vars, row))
            del_btn = ttk.Button(row, text="X", width=3, command=on_delete)
            del_btn.grid(row=0, column=4, padx=(4,0))
            row.pack(fill="x", pady=3)
            self.tr_rows.append((name_var, seq_vars, row))
            if prefill and prefill.get("sequence"):
                for st in prefill["sequence"]:
                    add_box(st)
            else:
                add_box("")
                add_box("")
        self.add_rule_row = add_rule_row
        ttk.Button(trlf, text="Add Rule", command=lambda: add_rule_row()).grid(row=1, column=0, sticky="w", pady=(6,0))

        toggles = ttk.LabelFrame(right, text="Other Metrics")
        toggles.grid(row=1, column=0, sticky="nsew")
        for i, (k, var) in enumerate(self.metrics_flags.items()):
            ttk.Checkbutton(toggles, text=k.replace("_", " ").title(), variable=var).grid(row=i//2, column=i%2, sticky="w")

        bh = ttk.LabelFrame(right, text="Business Hours")
        bh.grid(row=2, column=0, sticky="nsew", pady=(8,0))
        self.bh_start = tk.StringVar(value="09:00")
        self.bh_end = tk.StringVar(value="17:00")
        self.bh_tz = tk.StringVar(value="UTC")
        self.bh_excl_wknd = tk.BooleanVar(value=True)
        self.bh_holidays = tk.StringVar(value="")
        ttk.Label(bh, text="Start (HH:MM):").grid(row=0, column=0, sticky="w")
        ttk.Entry(bh, textvariable=self.bh_start, width=8).grid(row=0, column=1, sticky="w")
        ttk.Label(bh, text="End (HH:MM):").grid(row=0, column=2, sticky="w")
        ttk.Entry(bh, textvariable=self.bh_end, width=8).grid(row=0, column=3, sticky="w")
        ttk.Label(bh, text="Timezone:").grid(row=1, column=0, sticky="w")
        tz_combo = ttk.Combobox(bh, textvariable=self.bh_tz, values=sorted(pytz.all_timezones), width=28)
        tz_combo.grid(row=1, column=1, columnspan=3, sticky="we")
        ttk.Checkbutton(bh, text="Exclude weekends", variable=self.bh_excl_wknd).grid(row=2, column=0, columnspan=2, sticky="w")
        ttk.Label(bh, text="Holidays (YYYY-MM-DD, comma separated):").grid(row=3, column=0, columnspan=4, sticky="w")
        ttk.Entry(bh, textvariable=self.bh_holidays, width=40).grid(row=4, column=0, columnspan=4, sticky="we")

        bottom = ttk.LabelFrame(self, text="Configuration Management", padding=8)
        bottom.grid(row=1, column=0, columnspan=2, sticky="nsew", pady=(0,8))

        ttk.Label(bottom, text="Config Name:").grid(row=0, column=0, sticky="w")
        self.cfg_name_var = tk.StringVar()
        ttk.Entry(bottom, textvariable=self.cfg_name_var, width=30).grid(row=0, column=1, sticky="w")
        ttk.Button(bottom, text="Save Config", command=self.save_current_config).grid(row=0, column=2, padx=(8,0))
        ttk.Label(bottom, text="Load:").grid(row=0, column=3, padx=(16,4))
        self.cfg_combo = ttk.Combobox(bottom, values=list_configs(), state="readonly", width=30)
        self.cfg_combo.grid(row=0, column=4, sticky="we")
        ttk.Button(bottom, text="Load", command=self.load_selected_config).grid(row=0, column=5, padx=(6,0))

        self.grid_columnconfigure(0, weight=1)
        self.grid_columnconfigure(1, weight=1)
        self.grid_rowconfigure(0, weight=1)

    def _preview_value(self, v):
        if isinstance(v, dict):
            if "displayName" in v: return v["displayName"]
            if "name" in v: return v["name"]
            if "value" in v: return v["value"]
            return "{...}"
        if isinstance(v, list):
            return f"[{len(v)} item(s)]"
        if v is None:
            return ""
        s = str(v)
        return s if len(s) <= 200 else s[:197] + "..."

    def _on_tree_click(self, event):
        region = self.fields_tree.identify("region", event.x, event.y)
        if region != "cell":
            return
        col = self.fields_tree.identify_column(event.x)
        if col != "#1":
            return
        row_id = self.fields_tree.identify_row(event.y)
        if not row_id:
            return
        fid = row_id
        if fid in self.selected_field_ids:
            self.selected_field_ids.remove(fid)
            self.fields_tree.set(row_id, "selected", "")
        else:
            self.selected_field_ids.add(fid)
            self.fields_tree.set(row_id, "selected", "‚úì")

    def load_fields(self):
        key = self.issue_key_var.get().strip()
        if not key:
            messagebox.showerror("Error", "Enter an issue key.")
            return
        self.log(f"Loading issue {key} to fetch fields...")
        def worker():
            return self.client.get_issue(key, expand_changelog=False)
        def on_done(issue):
            fields = issue.get("fields", {})
            for item in self.fields_tree.get_children():
                self.fields_tree.delete(item)
            self.available_field_ids = list(fields.keys())
            for fid in self.available_field_ids:
                disp = self.field_id_to_name.get(fid, fid)
                val = self._preview_value(fields.get(fid))
                sel_mark = "‚úì" if fid in self.selected_field_ids else ""
                self.fields_tree.insert("", "end", iid=fid, values=(sel_mark, disp, val))
            self.log(f"Loaded {len(self.available_field_ids)} fields.")
        threading.Thread(target=lambda: self._run_worker(worker, on_done), daemon=True).start()

    def _run_worker(self, worker, on_done):
        try:
            res = worker()
        except Exception as e:
            self.log(f"Error: {e}")
            messagebox.showerror("Error", str(e))
            return
        self.after(0, lambda: on_done(res))

    def save_current_config(self):
        name = self.cfg_name_var.get().strip()
        if not name:
            messagebox.showerror("Error", "Please enter a configuration name.")
            return

        selected_ids = list(self.selected_field_ids)
        selected_names = [self.field_id_to_name.get(fid, fid) for fid in selected_ids]

        trules = []
        for name_var, seq_vars, _row in self.tr_rows:
            rule_name = name_var.get().strip()
            if not rule_name:
                continue
            seq = [v.get().strip() for v in seq_vars if v.get().strip()]
            if len(seq) < 2:
                continue
            trules.append({"name": rule_name, "sequence": seq})
        bh_cfg = {
            "start": self.bh_start.get().strip(),
            "end": self.bh_end.get().strip(),
            "timezone": self.bh_tz.get().strip() or "UTC",
            "exclude_weekends": bool(self.bh_excl_wknd.get()),
            "holidays": [h.strip() for h in self.bh_holidays.get().split(",") if h.strip()]
        }
        cfg = {
            "name": name,
            "selected_field_ids": selected_ids,
            "selected_field_names": selected_names,
            "transition_rules": trules,
            "metrics": {k: bool(v.get()) for k, v in self.metrics_flags.items()},
            "business_hours": bh_cfg
        }
        save_config(cfg)
        self.cfg_combo["values"] = list_configs()
        self.log(f"Saved configuration '{name}'.")

    def load_selected_config(self):
        name = self.cfg_combo.get()
        if not name:
            messagebox.showerror("Error", "Select a configuration to load.")
            return
        cfg = load_config(name)
        self.cfg_name_var.set(cfg.get("name", name))

        ids_from_cfg = cfg.get("selected_field_ids")
        if not ids_from_cfg:
            ids_from_cfg = cfg.get("selected_fields", [])
        self.selected_field_ids = set(ids_from_cfg)

        for iid in self.fields_tree.get_children():
            fid = iid
            self.fields_tree.set(iid, "selected", "‚úì" if fid in self.selected_field_ids else "")

        for _ in list(getattr(self, "tr_rows", [])):
            _[2].destroy()
        self.tr_rows = []
        for tr in cfg.get("transition_rules", []):
            self.add_rule_row(prefill=tr)

        m = cfg.get("metrics", {})
        for k, var in self.metrics_flags.items():
            var.set(bool(m.get(k, False)))

        bh = cfg.get("business_hours", {})
        self.bh_start.set(bh.get("start", "09:00"))
        self.bh_end.set(bh.get("end", "17:00"))
        self.bh_tz.set(bh.get("timezone", "UTC"))
        self.bh_excl_wknd.set(bool(bh.get("exclude_weekends", True)))
        self.bh_holidays.set(", ".join(bh.get("holidays", [])))

        self.log(f"Loaded configuration '{name}'.")

    def get_current_config(self):
        selected_ids = list(self.selected_field_ids)
        selected_names = [self.field_id_to_name.get(fid, fid) for fid in selected_ids]
        trules = []
        for name_var, seq_vars, _row in self.tr_rows:
            rule_name = name_var.get().strip()
            seq = [v.get().strip() for v in seq_vars if v.get().strip()]
            if rule_name and len(seq) >= 2:
                trules.append({"name": rule_name, "sequence": seq})
        return {
            "selected_field_ids": selected_ids,
            "selected_field_names": selected_names,
            "transition_rules": trules,
            "metrics": {k: bool(v.get()) for k, v in self.metrics_flags.items()},
            "business_hours": {
                "start": self.bh_start.get().strip(),
                "end": self.bh_end.get().strip(),
                "timezone": self.bh_tz.get().strip() or "UTC",
                "exclude_weekends": bool(self.bh_excl_wknd.get()),
                "holidays": [h.strip() for h in self.bh_holidays.get().split(",") if h.strip()]
            }
        }

class JQLTab(ttk.Frame):
    SPRINT_NAME_RE = re.compile(r"name=([^,\]]+)")

    def __init__(self, master, jira_client: JiraClient, config_tab: ConfigTab, log_fn, field_id_to_name):
        super().__init__(master)
        self.client = jira_client
        self.config_tab = config_tab
        self.log = log_fn
        self.field_id_to_name = field_id_to_name
        self._build_ui()

    def _build_ui(self):
        top = ttk.Frame(self, padding=6)
        top.grid(row=0, column=0, sticky="nsew")
        ttk.Label(top, text="JQL:").grid(row=0, column=0, sticky="w")
        self.jql_var = tk.StringVar()
        ttk.Entry(top, textvariable=self.jql_var, width=80).grid(row=0, column=1, sticky="we")
        ttk.Button(top, text="Search", command=self.search_jql).grid(row=0, column=2, padx=(6,0))
        self.count_var = tk.StringVar(value="Matches: 0")
        ttk.Label(top, textvariable=self.count_var).grid(row=0, column=3, padx=(10,0))
        ttk.Button(top, text="Export CSV", command=self.export_csv).grid(row=0, column=4, padx=(6,0))
        ttk.Button(top, text="Export JSON", command=self.export_json).grid(row=0, column=5, padx=(6,0))

        top.grid_columnconfigure(1, weight=1)

        pb_frame = ttk.Frame(self, padding=(6,0))
        pb_frame.grid(row=1, column=0, sticky="we")
        self.pb = ttk.Progressbar(pb_frame, orient="horizontal", mode="determinate", value=0)
        self.pb.grid(row=0, column=0, sticky="we")
        self.stage_var = tk.StringVar(value="")
        ttk.Label(pb_frame, textvariable=self.stage_var).grid(row=1, column=0, sticky="w", pady=(2,0))
        pb_frame.grid_columnconfigure(0, weight=1)

        self.grid_rowconfigure(2, weight=1)
        self.grid_columnconfigure(0, weight=1)

    def search_jql(self):
        jql = self.jql_var.get().strip()
        if not jql:
            messagebox.showerror("Error", "Enter JQL.")
            return
        self.log(f"Searching JQL: {jql}")
        def worker():
            keys, total = self.client.search_jql(jql, max_results=100, fields=["key"], expand_changelog=False)
            return keys, total
        def on_done(res):
            keys, total = res
            self.count_var.set(f"Matches: {total}")
            self.log(f"Found {total} issue(s).")
            self._last_keys = keys
        threading.Thread(target=lambda: self._run_worker(worker, on_done), daemon=True).start()

    def export_csv(self):
        jql = self.jql_var.get().strip()
        if not jql:
            messagebox.showerror("Error", "Enter JQL.")
            return
        cfg = self.config_tab.get_current_config()
        filepath = filedialog.asksaveasfilename(
            title="Save CSV",
            defaultextension=".csv",
            filetypes=[("CSV files","*.csv")]
        )
        if not filepath:
            return
        self.log("Starting export...")
        self.pb["value"] = 0
        self.pb.update_idletasks()

        def progress_cb(stage, done, total):
            self.stage_var.set(stage)
            self.pb["maximum"] = total if total else 1
            self.pb["value"] = min(done, total) if total else done

        def worker():
            headers, row_iter = export_csv(
                jira_client=self.client,
                jql=jql,
                cfg=cfg,
                field_id_to_name=self.field_id_to_name,
                format_field_fn=self._format_field,
                business_hours_overlap=business_hours_overlap,
                progress_cb=progress_cb
            )
            with open(filepath, "w", newline="", encoding="utf-8") as f:
                import csv as _csv
                writer = _csv.DictWriter(f, fieldnames=headers)
                writer.writeheader()
                for _row in row_iter():
                    writer.writerow(_row)
            return True

        def on_done(_):
            self.stage_var.set("")
            self.log("Export completed.")
            messagebox.showinfo("Done", "CSV export completed.")

        threading.Thread(target=lambda: self._run_worker(worker, on_done), daemon=True).start()

    def export_json(self):
        jql = self.jql_var.get().strip()
        if not jql:
            messagebox.showerror("Error", "Enter JQL.")
            return
        folder = filedialog.askdirectory(title="Select folder to save JSON issues")
        if not folder:
            return
        self.log("Starting JSON export...")
        self.pb["value"] = 0
        self.pb.update_idletasks()

        def progress_cb(stage, done, total):
            self.stage_var.set(stage)
            self.pb["maximum"] = total if total else 1
            self.pb["value"] = min(done, total) if total else done

        def worker():
            export_json(
                jira_client=self.client,
                jql=jql,
                field_id_to_name=self.field_id_to_name,
                folder_path=folder,
                progress_cb=progress_cb
            )
            return True

        def on_done(_):
            self.stage_var.set("")
            self.log("JSON export completed.")
            messagebox.showinfo("Done", "JSON export completed.")

        threading.Thread(target=lambda: self._run_worker(worker, on_done), daemon=True).start()

    def _parse_sprint_blob(self, s):
        m = self.SPRINT_NAME_RE.search(s or "")
        return m.group(1) if m else s

    def _format_field(self, fid, val):
        name = self.field_id_to_name.get(fid, fid)
        if isinstance(val, list) and name.lower() == "sprint":
            sprints = []
            for s in val:
                if isinstance(s, dict):
                    nm = s.get("name") or s.get("id")
                    if s.get("state"):
                        nm = f"{nm} ({s['state']})"
                    sprints.append(str(nm))
                else:
                    sprints.append(self._parse_sprint_blob(str(s)))
            return " | ".join(sprints)
        if name.lower() == "fix versions" and isinstance(val, list):
            return ", ".join([v.get("name") for v in val if isinstance(v, dict) and v.get("name")])
        if name.lower() == "affects versions" and isinstance(val, list):
            return ", ".join([v.get("name") for v in val if isinstance(v, dict) and v.get("name")])
        if name.lower() == "components" and isinstance(val, list):
            return ", ".join([v.get("name") for v in val if isinstance(v, dict) and v.get("name")])
        if isinstance(val, list):
            items = []
            for x in val:
                if isinstance(x, dict):
                    items.append(x.get("displayName") or x.get("name") or x.get("value") or x.get("key") or str(x))
                else:
                    items.append(str(x))
            return ", ".join(items)
        if isinstance(val, dict):
            if "displayName" in val: return val["displayName"]
            if "name" in val: return val["name"]
            if "value" in val: return val["value"]
            if "key" in val: return val["key"]
            return json.dumps(val, ensure_ascii=False)
        return "" if val is None else str(val)

    def _run_worker(self, worker, on_done):
        try:
            res = worker()
        except Exception as e:
            self.log(f"Error: {e}")
            messagebox.showerror("Error", str(e))
            return
        self.after(0, lambda: on_done(res))

class MainWindow(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Jira Metrics")
        self.geometry("1100x720")
        self.minsize(950, 620)
        ensure_app_dirs()

        self.log_console = LogConsole(self, height=8)
        self.nb = ttk.Notebook(self)
        self.nb.grid(row=0, column=0, sticky="nsew")
        self.log_console.grid(row=1, column=0, sticky="nsew")
        self.grid_rowconfigure(0, weight=1)
        self.grid_rowconfigure(1, weight=0)
        self.grid_columnconfigure(0, weight=1)

        self._client = None
        self._config_tab = None
        self._jql_tab = None

        self.after(100, self.open_login)

    def log(self, msg):
        print(msg)
        self.log_console.write(msg)

    def open_login(self):
        LoginWindow(self, on_success=self.on_login, log_fn=self.log)

    def on_login(self, client: JiraClient):
        self._client = client
        try:
            fields = self._client.get_fields()
        except Exception as e:
            self.log(f"Failed to load fields metadata: {e}")
            fields = []
        field_id_to_name = {}
        field_name_to_id = {}
        for f in fields:
            fid = f.get("id")
            fname = f.get("name")
            if fid and fname:
                field_id_to_name[fid] = fname
                field_name_to_id.setdefault(fname, fid)

        self._config_tab = ConfigTab(self.nb, jira_client=self._client, log_fn=self.log,
                                     field_id_to_name=field_id_to_name, field_name_to_id=field_name_to_id)
        self._jql_tab = JQLTab(self.nb, jira_client=self._client, config_tab=self._config_tab,
                               log_fn=self.log, field_id_to_name=field_id_to_name)
        self.nb.add(self._config_tab, text="Configuration")
        self.nb.add(self._jql_tab, text="JQL Search")
        self.log("Ready.")

if __name__ == "__main__":
    MainWindow().mainloop()
```

## Statistics

- Total Files: 5
- Total Characters: 60474
- Total Tokens: 0
